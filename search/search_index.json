{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Jordy's Datamining Welcome to Jordy's Datamining Di sini kita akan mempelajari metode - metode yang biasa terdapat pada datamining . . . . . . . . . . . . . . . . . . . . . . Penyusun NAMA : JURDI BIBIT PAMUNGKAS NIM : 170441100015 KELAS : DATAMINING A PRODI : SISTEM INFORMASI","title":"Welcome to Jordy's Datamining"},{"location":"#jordys-datamining","text":"","title":"Jordy's Datamining"},{"location":"#welcome-to-jordys-datamining","text":"Di sini kita akan mempelajari metode - metode yang biasa terdapat pada datamining . . . . . . . . . . . . . . . . . . . . . .","title":"Welcome to Jordy's Datamining"},{"location":"#penyusun","text":"NAMA : JURDI BIBIT PAMUNGKAS NIM : 170441100015 KELAS : DATAMINING A PRODI : SISTEM INFORMASI","title":"Penyusun"},{"location":"clustering/","text":"K-Means Clustering Apa itu K-Means Clustering? Clustering adalah metode penganalisaan data, yang sering dimasukkan sebagai salah satu metode Data Mining, yang tujuannya adalah untuk mengelompokkan data dengan karakteristik yang sama ke suatu 'wilayah' yang sama dan data dengan karakteristik yang berbeda ke 'wilayah' yang lain. K-Means Clustering merupakan salah satu metode yang dapat digunakan untuk membagi sejumlah objek ke dalam partisi-partisi berdasarkan kategori-kategori yang ada dengan melihat titik tengah yang diberikan. Peng-cluster-an objek dilihat dari jarak objek dengan titik tengah yang paling dekat. Setelah mengetahui titik tengah terdekat, objek tersebut akan diklasifikasikan sebagai anggota dari kategori tersebut Pada umumnya tujuan dari algoritma ini ialah membagi data atau disebut dengan mempartisi data yang ada ke dalam bentuk satu maupun lebih clusternya, membagi menjadi beberapa kelompok cluster. Pada algoritma ini bersifat menerima masukan dari berupa data tanpa adanya label kelas. Berbanding balik dengan sifat metode supervised learning yang menerima masukan dari berupa vektor data dan memiliki label data. Metode ini akan melakukan pembagian data ke dalam satu cluster yang sama apabila ada data yang mempunyai bentuk karakteristik berbeda akan di tempatkan ke dalam cluster yang lain Langkah - langkah K-Means Clustering Memilih jumlah cluster awal (K) yang ingin dibuat. Memilih titik secara random sebanyak K buah, di mana titik ini akan menjadi pusat ( centroid ) dari masing-masing kelompok ( clusters ). Dari dataset yang kita miliki, buat dataset yang terdekat dengan titik centroid sebagai bagian dari cluster tersebut. Sehingga secara total akan terbentuk clusters sebanyak K buah. Lakukan kalkulasi, dan tempatkan pusat centroid yang baru untuk setiap cluster -nya. Langkah ini bisa disebut juga dengan istilah penyempurnaan centroid . Dari dataset yang kita miliki ambil titik centroid terdekat, sehingga dataset tadi menjadi bagian dari cluster tersebut. Jika masih ada data yang berubah kelompok (pindah cluster ), kembali ke langkah 4. Jika tidak, maka cluster yang terbentuk sudah baik. Kelebihan dan Kekurangan Kelebihan k-means : Mudah dilakukan saat pengimpelementasian dan di jalankan. Waktu yang di butuhkan untuk melakukan pembelajaran relatif lebih cepat. Sangat fleksibel, adaptasi yang mudah untuk di lakukan Sangat umum penggunaannya. Menggunakan prinsip yang sederhana dapat di jelaskan dalam non-statistik. Kekurangan dari k-means : Sebelum algoritma di jalankan, titik K diinisialisasikan secara random sehingga pengelompokan data yang di dapatkan bisa berbeda-beda. Namun apabila nilai yang diperoleh acak untuk penginisialisasi kurang baik maka pengelompokan yang didapatkn menjadi tidak optimal. Apabila terjebak dalam kasus yang biasanya di sebut dengan curse of dimensionality. Hal ini pun akan terjadi apabila salah satu data untuk melakukan pelatihan mempunyai dimensi yang sangat banyak, sebagai contoh; jika ada data pelatihan yang terdiri dari 2 buah atribut saja maka dimensinya ada 2 dimensi pula, namun akan berbeda jika ada 20 atribut maka akan ada 20 dimensi yang di miliki. Adapun salah satu dari cara kerja algoritma cluster ini ialah untuk mencari jarak terdekat dari antara k titik dangan titik lainnya. Apabila ingin mencari jarak untuk antar titik dari 2 dimensi hal itu masih mudah untuk di lakukan, namun bagaimana dengan 20 buah dimensi hal tersebut akan menjadi lebih sulit untuk di lakukan pencarian jarak. Apabila hanya ada terdapat beberapa buah titik sampel data yang ada, maka hal yang mudah untuk melakukan penghitungan dan mencari jarak titik terdekat dengan k titik yang telah di lakukan inisialisasi yang secara acak. Namun jika ada banyak titik data, misalkan satu juta data, maka perhitungan dan pencarian titik terdekat akan sangat membutuhkan waktu yang lama. Proses tersebut dapat dipercepat namun dibutuhkan sebuah struktur data yang lebih rumit seperti kD-tree atau hashing untuk melakukan proses tersebut. Adanya penggunaan k buah random, tidak ada jaminan untuk menemukan kumpulan cluster yang optimal. Studi Kasus** Seorang data scientist profesional diminta oleh klien untuk menganalisis data customers yang berkunjung ke suatu Alfamart. Mereka data pelanggan setia, namun mereka bingung cara mengelompokkan data ini, sehingga nantinya pengelompokan ini bisa mereka gunakan untuk semakin memperkuat hubungan mereka terhadap konsumen. Misal untuk penguatan marketing, strategi penawaran yang tepat, kebutuhan apa saja yang cocok bagi mereka, dll. Kebutuhan Sebelum memulai project sebaiknya lakukan hal - hal berikut, jika sudah silahkan bisa langsung menuju ke script program di bawah. install bahasa pemrograman python, bisa anda download di sini Dataset csv, bisa anda download datasetnya di sini . Install numpy menggunakan pip : pip install numpy Install matplotlib menggunakan pip : pip install matplotlib Install pandas menggunakan pip : pip install pandas Script Program # Mengimpor library import numpy as np import matplotlib.pyplot as plt import pandas as pd # Mengimpor dataset dataset = pd.read_csv('Data_Customers_Alfamart.csv') X = dataset.iloc[:, [3, 4]].values # Menggunakan metode elbow untuk menentukan angka cluster yang tepat from sklearn.cluster import KMeans wcss = [] for i in range(1, 9): kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 187) kmeans.fit(X) wcss.append(kmeans.inertia_) plt.plot(range(1, 9), wcss) plt.title('Metode Elbow') plt.xlabel('Jumlah Clusters') plt.ylabel('WCSS') plt.show() # Menjalankan K-Means Clustering ke dataset kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 187) y_kmeans = kmeans.fit_predict(X) # Visualisasi hasil clusters plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'blue', label = 'Cluster 1') plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'red', label = 'Cluster 2') plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'yellow', label = 'Cluster 3') plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'green', label = 'Cluster 4') plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 50, c = 'black', label = 'Centroids') plt.title('Clusters Customers Alfamart') plt.xlabel('Pendapatan/bulan (Juta)') plt.ylabel('Rating Belanja (1-100)') plt.legend() plt.show() Penjelasan Script Line 2 sampai 4 mengimpor library yang dibutuhkan Line 7, mengimpor dataset Line 8, melakukan slicing, dari dataset yang dimiliki (Data_Customers_Alfamart). Kita hanya memerlukan kolom ke 3 (Penghasilan) dan 4 (Rating Belanja) saja Line 11, mengimpor library K-Means. Line 12, membuat list WCSS (mempersiapkan perhitungan WCSS). Line 13 adalah perintah looping, perlu diingat bahwa kita ingin melakukan looping 8 kali. Oleh karena itu script di atas ditulis range(1,9), karena angka 9 tidak diikutkan oleh python. Line 14 adalah menuliskan objek kmeans untuk melakukan algoritma K-Means. Selanjutnya perintah pertama adalah KMeans (kapital K dan M), yang merupakan class dari library K-Means yang diimpor di line 11, dengan beberapa parameter n_clusters yang merupakan jumlah kluster, diikuti dengan parameter kedua init yang merupakan pemilihan jumlah K di awal (kali ini kita gunakan K++, agar tidak terkena jebakan centroid. Kemudian parameter yang terakhir adalah random_state = 187. Random state ini seperti seed pada R, yang jika dipilih 187, maka ketika kita memilih 187 di kesempatan yang berbeda, maka bilangan random yang dihasilkan akan sama. Line 15 merupakan perintah agar objek kmeans di line 14, digunakan untuk mengolah data X yang sudah kita definisikan di line 8. Line 16 merupakan perintah untuk menghitung WCSS dengan menuliskan perintah append setelah wcss. Append merupakan method di python untuk menambahkan objek. Algoritma wcss dituliskan dengan perintah kmeans.inertia_ (dengan underscore). Line 17 merupakan perintah untuk menampilkan plot. Sumbu x pada plot adalah jumlah kluster dari 1-8, maka ditulis range(1,9). Sumbu y nya adalah skor wcss yang dihitung di line 16. Line 18-20 adalah perintah plot untuk estetika, seperti nama sumbu x, sumbu y dll. Line 21 adalah perintah menampilkan plotnya. Jika benar, maka tampilan plotnya akan tampak sebagai berikut: ( Within Cluster Sum of Squares ): Hasil perhitungan WCSS dari K=1 sampai K=8 Melalui gambar di atas, dapat dilihat bahwa bentuk elbow (siku) terlihat saat jumlah kluster adalah 4. Oleh karena itu, kita tentukan bahwa jumlah K yang baik adalah 4. Note: Jika pembaca berpendapat bahwa bentuk siku juga terlihat pada K=3, maka itu juga benar. Dalam kondisi seperti ini, di mana K=3 dan K=4 menunjukkan bentuk siku, kita pilih yang nilai K nya lebih besar, dalam hal ini K=4. Sekarang saatnya kita memilih jumlah kluster=4. Line 24 adalah perintah melakukan K-Means clustering terhadap objek kmeans. Perintahnya mirip dengan line 14, namun kali ini parameter n_clusters diisi dengan 4. Line 25 adalah melakukan prediksi seperti apa pengelompokan klusternya jika kita pilih K=4. Kita siapkan objek y_kmeans (tentu saja pemilihan nama ini bebas) dengan method bukan fit melainkan fit_predict terhadap variabel X yang sudah didefinisikan di line 8. Line 28-38 menampilkan hasil clusteringnya. Line 38 adalah perintah untuk menampilkan plotnya. Jika benar, maka tampilan klusternya tampak sebagai berikut: Melalui gambar di atas bisa dilihat pembagian data points dibagi menjadi 4 kluster, kluster 1 berwarna biru, kluster 2 berwarna merah, kluster 3 berwarna kuning, dan kluster 4 berwarna hijau. Tiap kluster juga sudah terlihat baik dan semua data points masuk ke dalam kluster masing-masing.","title":"K-Means Clustering"},{"location":"clustering/#k-means-clustering","text":"","title":"K-Means Clustering"},{"location":"clustering/#apa-itu-k-means-clustering","text":"Clustering adalah metode penganalisaan data, yang sering dimasukkan sebagai salah satu metode Data Mining, yang tujuannya adalah untuk mengelompokkan data dengan karakteristik yang sama ke suatu 'wilayah' yang sama dan data dengan karakteristik yang berbeda ke 'wilayah' yang lain. K-Means Clustering merupakan salah satu metode yang dapat digunakan untuk membagi sejumlah objek ke dalam partisi-partisi berdasarkan kategori-kategori yang ada dengan melihat titik tengah yang diberikan. Peng-cluster-an objek dilihat dari jarak objek dengan titik tengah yang paling dekat. Setelah mengetahui titik tengah terdekat, objek tersebut akan diklasifikasikan sebagai anggota dari kategori tersebut Pada umumnya tujuan dari algoritma ini ialah membagi data atau disebut dengan mempartisi data yang ada ke dalam bentuk satu maupun lebih clusternya, membagi menjadi beberapa kelompok cluster. Pada algoritma ini bersifat menerima masukan dari berupa data tanpa adanya label kelas. Berbanding balik dengan sifat metode supervised learning yang menerima masukan dari berupa vektor data dan memiliki label data. Metode ini akan melakukan pembagian data ke dalam satu cluster yang sama apabila ada data yang mempunyai bentuk karakteristik berbeda akan di tempatkan ke dalam cluster yang lain","title":"Apa itu K-Means Clustering?"},{"location":"clustering/#langkah-langkah-k-means-clustering","text":"Memilih jumlah cluster awal (K) yang ingin dibuat. Memilih titik secara random sebanyak K buah, di mana titik ini akan menjadi pusat ( centroid ) dari masing-masing kelompok ( clusters ). Dari dataset yang kita miliki, buat dataset yang terdekat dengan titik centroid sebagai bagian dari cluster tersebut. Sehingga secara total akan terbentuk clusters sebanyak K buah. Lakukan kalkulasi, dan tempatkan pusat centroid yang baru untuk setiap cluster -nya. Langkah ini bisa disebut juga dengan istilah penyempurnaan centroid . Dari dataset yang kita miliki ambil titik centroid terdekat, sehingga dataset tadi menjadi bagian dari cluster tersebut. Jika masih ada data yang berubah kelompok (pindah cluster ), kembali ke langkah 4. Jika tidak, maka cluster yang terbentuk sudah baik.","title":"Langkah - langkah K-Means Clustering"},{"location":"clustering/#kelebihan-dan-kekurangan","text":"Kelebihan k-means : Mudah dilakukan saat pengimpelementasian dan di jalankan. Waktu yang di butuhkan untuk melakukan pembelajaran relatif lebih cepat. Sangat fleksibel, adaptasi yang mudah untuk di lakukan Sangat umum penggunaannya. Menggunakan prinsip yang sederhana dapat di jelaskan dalam non-statistik. Kekurangan dari k-means : Sebelum algoritma di jalankan, titik K diinisialisasikan secara random sehingga pengelompokan data yang di dapatkan bisa berbeda-beda. Namun apabila nilai yang diperoleh acak untuk penginisialisasi kurang baik maka pengelompokan yang didapatkn menjadi tidak optimal. Apabila terjebak dalam kasus yang biasanya di sebut dengan curse of dimensionality. Hal ini pun akan terjadi apabila salah satu data untuk melakukan pelatihan mempunyai dimensi yang sangat banyak, sebagai contoh; jika ada data pelatihan yang terdiri dari 2 buah atribut saja maka dimensinya ada 2 dimensi pula, namun akan berbeda jika ada 20 atribut maka akan ada 20 dimensi yang di miliki. Adapun salah satu dari cara kerja algoritma cluster ini ialah untuk mencari jarak terdekat dari antara k titik dangan titik lainnya. Apabila ingin mencari jarak untuk antar titik dari 2 dimensi hal itu masih mudah untuk di lakukan, namun bagaimana dengan 20 buah dimensi hal tersebut akan menjadi lebih sulit untuk di lakukan pencarian jarak. Apabila hanya ada terdapat beberapa buah titik sampel data yang ada, maka hal yang mudah untuk melakukan penghitungan dan mencari jarak titik terdekat dengan k titik yang telah di lakukan inisialisasi yang secara acak. Namun jika ada banyak titik data, misalkan satu juta data, maka perhitungan dan pencarian titik terdekat akan sangat membutuhkan waktu yang lama. Proses tersebut dapat dipercepat namun dibutuhkan sebuah struktur data yang lebih rumit seperti kD-tree atau hashing untuk melakukan proses tersebut. Adanya penggunaan k buah random, tidak ada jaminan untuk menemukan kumpulan cluster yang optimal.","title":"Kelebihan dan Kekurangan"},{"location":"clustering/#studi-kasus","text":"Seorang data scientist profesional diminta oleh klien untuk menganalisis data customers yang berkunjung ke suatu Alfamart. Mereka data pelanggan setia, namun mereka bingung cara mengelompokkan data ini, sehingga nantinya pengelompokan ini bisa mereka gunakan untuk semakin memperkuat hubungan mereka terhadap konsumen. Misal untuk penguatan marketing, strategi penawaran yang tepat, kebutuhan apa saja yang cocok bagi mereka, dll.","title":"Studi Kasus**"},{"location":"clustering/#kebutuhan","text":"Sebelum memulai project sebaiknya lakukan hal - hal berikut, jika sudah silahkan bisa langsung menuju ke script program di bawah. install bahasa pemrograman python, bisa anda download di sini Dataset csv, bisa anda download datasetnya di sini . Install numpy menggunakan pip : pip install numpy Install matplotlib menggunakan pip : pip install matplotlib Install pandas menggunakan pip : pip install pandas","title":"Kebutuhan"},{"location":"clustering/#script-program","text":"# Mengimpor library import numpy as np import matplotlib.pyplot as plt import pandas as pd # Mengimpor dataset dataset = pd.read_csv('Data_Customers_Alfamart.csv') X = dataset.iloc[:, [3, 4]].values # Menggunakan metode elbow untuk menentukan angka cluster yang tepat from sklearn.cluster import KMeans wcss = [] for i in range(1, 9): kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 187) kmeans.fit(X) wcss.append(kmeans.inertia_) plt.plot(range(1, 9), wcss) plt.title('Metode Elbow') plt.xlabel('Jumlah Clusters') plt.ylabel('WCSS') plt.show() # Menjalankan K-Means Clustering ke dataset kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 187) y_kmeans = kmeans.fit_predict(X) # Visualisasi hasil clusters plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'blue', label = 'Cluster 1') plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'red', label = 'Cluster 2') plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'yellow', label = 'Cluster 3') plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'green', label = 'Cluster 4') plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 50, c = 'black', label = 'Centroids') plt.title('Clusters Customers Alfamart') plt.xlabel('Pendapatan/bulan (Juta)') plt.ylabel('Rating Belanja (1-100)') plt.legend() plt.show()","title":"Script Program"},{"location":"clustering/#penjelasan-script","text":"Line 2 sampai 4 mengimpor library yang dibutuhkan Line 7, mengimpor dataset Line 8, melakukan slicing, dari dataset yang dimiliki (Data_Customers_Alfamart). Kita hanya memerlukan kolom ke 3 (Penghasilan) dan 4 (Rating Belanja) saja Line 11, mengimpor library K-Means. Line 12, membuat list WCSS (mempersiapkan perhitungan WCSS). Line 13 adalah perintah looping, perlu diingat bahwa kita ingin melakukan looping 8 kali. Oleh karena itu script di atas ditulis range(1,9), karena angka 9 tidak diikutkan oleh python. Line 14 adalah menuliskan objek kmeans untuk melakukan algoritma K-Means. Selanjutnya perintah pertama adalah KMeans (kapital K dan M), yang merupakan class dari library K-Means yang diimpor di line 11, dengan beberapa parameter n_clusters yang merupakan jumlah kluster, diikuti dengan parameter kedua init yang merupakan pemilihan jumlah K di awal (kali ini kita gunakan K++, agar tidak terkena jebakan centroid. Kemudian parameter yang terakhir adalah random_state = 187. Random state ini seperti seed pada R, yang jika dipilih 187, maka ketika kita memilih 187 di kesempatan yang berbeda, maka bilangan random yang dihasilkan akan sama. Line 15 merupakan perintah agar objek kmeans di line 14, digunakan untuk mengolah data X yang sudah kita definisikan di line 8. Line 16 merupakan perintah untuk menghitung WCSS dengan menuliskan perintah append setelah wcss. Append merupakan method di python untuk menambahkan objek. Algoritma wcss dituliskan dengan perintah kmeans.inertia_ (dengan underscore). Line 17 merupakan perintah untuk menampilkan plot. Sumbu x pada plot adalah jumlah kluster dari 1-8, maka ditulis range(1,9). Sumbu y nya adalah skor wcss yang dihitung di line 16. Line 18-20 adalah perintah plot untuk estetika, seperti nama sumbu x, sumbu y dll. Line 21 adalah perintah menampilkan plotnya. Jika benar, maka tampilan plotnya akan tampak sebagai berikut: ( Within Cluster Sum of Squares ): Hasil perhitungan WCSS dari K=1 sampai K=8 Melalui gambar di atas, dapat dilihat bahwa bentuk elbow (siku) terlihat saat jumlah kluster adalah 4. Oleh karena itu, kita tentukan bahwa jumlah K yang baik adalah 4. Note: Jika pembaca berpendapat bahwa bentuk siku juga terlihat pada K=3, maka itu juga benar. Dalam kondisi seperti ini, di mana K=3 dan K=4 menunjukkan bentuk siku, kita pilih yang nilai K nya lebih besar, dalam hal ini K=4. Sekarang saatnya kita memilih jumlah kluster=4. Line 24 adalah perintah melakukan K-Means clustering terhadap objek kmeans. Perintahnya mirip dengan line 14, namun kali ini parameter n_clusters diisi dengan 4. Line 25 adalah melakukan prediksi seperti apa pengelompokan klusternya jika kita pilih K=4. Kita siapkan objek y_kmeans (tentu saja pemilihan nama ini bebas) dengan method bukan fit melainkan fit_predict terhadap variabel X yang sudah didefinisikan di line 8. Line 28-38 menampilkan hasil clusteringnya. Line 38 adalah perintah untuk menampilkan plotnya. Jika benar, maka tampilan klusternya tampak sebagai berikut: Melalui gambar di atas bisa dilihat pembagian data points dibagi menjadi 4 kluster, kluster 1 berwarna biru, kluster 2 berwarna merah, kluster 3 berwarna kuning, dan kluster 4 berwarna hijau. Tiap kluster juga sudah terlihat baik dan semua data points masuk ke dalam kluster masing-masing.","title":"Penjelasan Script"},{"location":"nearestneighbors/","text":"K-Nearest Neighbors Apa itu k-NN? K-Nearest Neighbors (k-NN) . Jika diartikan ke dalam bahasa Indonesia, artinya adalah tetangga terdekat sebanyak K buah. K-Nearest Neighbor (K-NN) adalah suatu metode yang menggunakan algoritma supervised dimana hasil dari sampel uji yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada K-NN. Tujuan dari algoritma ini adalah mengklasifikasi objek baru berdasakan atribut dan sampel latih. pengklasifikasian tidak menggunakan model apapun untuk dicocokkan dan hanya berdasarkan pada memori. Diberikan titik uji, akan ditemukan sejumlah K objek (titik training) yang paling dekat dengan titik uji. Klasifikasi menggunakan voting terbanyak di antara klasifikasi dari K objek. Algoritma K-NN menggunakan klasifikasi ketetanggaan sebagai nilai prediksi dari sample uji yang baru. Dekat atau jauhnya tetangga biasanya dihitung berdasarkan jarak Eucledian. Algoritma metode KNN sangatlah sederhana, bekerja dengan berdasarkan pada jarak terpendek dari sample uji ke sample latih untuk menentukan KNN nya. Setelah mengumpulkan KNN, kemudian diambil mayoritas dari KNN untuk dijadikan prediksi dari sample uji. Langkah - langkah k-NN Tentukan jumlah kelompok neighbors (K) nya. Umumnya adalah 5. Ambil data K terdekat (K neighbors) dari data terbaru (umumnya 5 buah K) berdasarkan jarak euclidean antar keduanya. Dari K-neighbors ini, hitung berapa banyak data poin yang masuk di masing-masing kategori. Masukkan data baru ini ke dalam kelompok yang memiliki jumlah K-neighbors terbanyak Kelebihan dan Kekurangan k-NN Kelebihan k-NN : memiliki beberapa kelebihan yaitu bahwa dia tangguh terhadap training data yang noisy dan efektif apabila data latih nya besar. Kelemahan dari k-NN k-NN perlu menentukan nilai dari parameter K (jumlah dari tetangga terdekat) Pembelajaran berdasarkan jarak tidak jelas mengenai jenis jarak apa yang harus digunakan dan atribut mana yang harus digunakan untuk mendapatkan hasil yang terbaik Biaya komputasi cukup tinggi karena diperlukan perhitungan jarak dari tiap sample uji pada keseluruhan sample latih. Studi Kasus Seorang pemilik toko hp ingin mecari tahu solusi iklan di internet, di mana ia memiliki data pelanggannya. Melalui data penghasilan dan usia. Pemilik hp tersebut ingin mengiklankan produknya di kelompok yang memiliki kemungkinan untuk membeli hp nya lebih tinggi. Sehingga nantinya klasifikasi ini bisa digunakan oleh pemilik toko hp untuk semakin memperkuat hubungan mereka terhadap konsumen. Misal untuk penguatan marketing, strategi penawaran yang tepat, tipe hp apa saja yang cocok bagi mereka, dll. Kebutuhan Sebelum memulai project sebaiknya lakukan hal - hal berikut, jika sudah silahkan bisa langsung menuju ke script program di bawah. install bahasa pemrograman python, bisa anda download di sini Dataset csv, bisa anda download datasetnya di sini . Install numpy menggunakan pip : pip install numpy Install matplotlib menggunakan pip : pip install matplotlib Install pandas menggunakan pip : pip install pandas Script Program # Mengimpor library import numpy as np import matplotlib.pyplot as plt import pandas as pd # Mengimpor dataset dataset = pd.read_csv('Data_Customers_HP.csv') X = dataset.iloc[:, [2, 3]].values y = dataset.iloc[:, 4].values # Membagi dataset menjadi Training set and Test set from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) # Feature Scaling from sklearn.preprocessing import StandardScaler sc = StandardScaler() X_train = sc.fit_transform(X_train) X_test = sc.transform(X_test) # Membuat model k-NN from sklearn.neighbors import KNeighborsClassifier classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2) classifier.fit(X_train, y_train) # Memprediksi Test set y_pred = classifier.predict(X_test) # Membuat Confusion Matrix from sklearn.metrics import confusion_matrix cm = confusion_matrix(y_test, y_pred) # Visualisasi hasil Training set from matplotlib.colors import ListedColormap X_set, y_set = X_train, y_train X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01)) plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('grey', 'black'))) plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('yellow', 'red'))(i), label = j) plt.title('K-NN (Training set)') plt.xlabel('Usia') plt.ylabel('Penghasilan/bulan') plt.legend() plt.show() Penjelasan Script Line 1-4 mengimpor library yang diperlukan. Line 7 mengimpor dataset. Line 8 mendefinisikan variabel X yaitu kolom usia dan penghasilan/bulan. Line 9 mendefinisikan variabel y yaitu keputusan beli/tidak. Line 12 mengimpor library dari sklearn untuk membagi dataset ke dalam training dan test set dengan konfigurasi 75:25 dan random number generator 0. Line 13 mendefinisikan variabel training dan test set. Line 16-19 melakukan feature scaling. Line 22 mengimpor library k-NN. Line 23 adalah mendefinisikan variabel classifier sebagai model k-NN. T kita memilih jumlah K 5 sesuai default nya. Kemudian metric kit pilih \u2018minkowski\u2019, dan p kita isi 2, karena menggunakan euclidean distance Line 24 mengaplikasikan model ini terhadap X_train dan y_train, karena kita ingin melatih modelnya dari training set. Line 27 adalah mendefinisikan variabel y_pred untuk memprediksi test set. Kita memprediksinya dari X_test, yang nantinya y_pred ini akan dibandingkan dengan y_test. Jika y_pred hasilnya mendekati y_test, maka bisa disimpulkan performanya cukup baik. Line 30 mengimpor library confusion_matrix dari sklearn untuk membuat confusion_matrix (CM)-nya. CM adalah perbandingan antara benar dan salah antara y_pred dengan y_test. Line 31 membuat variabel cm sebagai confusion matrix nya. Line 34-49 adalah perintah untuk visualisasi model k-NN terhadap training set. Hasilnya akan tampak sebagai berikut: Tampilan model k-NN dari training set. Gambar ini adalah hasil prediksi keputusan beli/tidak berdasarkan usia dan penghasilan/bulan yang dimiliki customers. Pada gambar di atas dapat kita lihat bahwa zona abu-abu adalah kelompok di mana pelanggan memutuskan untuk tidak membeli, sementara zona hitam adalah kelompok pelanggan memutuskan untuk membeli. Titik-titik kuning adalah data-data pelanggan yang memutuskan untuk tidak membeli, sedangkan titik-titik merah adalah data-data pelanggan yang memutuskan untuk membeli.","title":"K-Nearest Neighbors"},{"location":"nearestneighbors/#k-nearest-neighbors","text":"","title":"K-Nearest Neighbors"},{"location":"nearestneighbors/#apa-itu-k-nn","text":"K-Nearest Neighbors (k-NN) . Jika diartikan ke dalam bahasa Indonesia, artinya adalah tetangga terdekat sebanyak K buah. K-Nearest Neighbor (K-NN) adalah suatu metode yang menggunakan algoritma supervised dimana hasil dari sampel uji yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada K-NN. Tujuan dari algoritma ini adalah mengklasifikasi objek baru berdasakan atribut dan sampel latih. pengklasifikasian tidak menggunakan model apapun untuk dicocokkan dan hanya berdasarkan pada memori. Diberikan titik uji, akan ditemukan sejumlah K objek (titik training) yang paling dekat dengan titik uji. Klasifikasi menggunakan voting terbanyak di antara klasifikasi dari K objek. Algoritma K-NN menggunakan klasifikasi ketetanggaan sebagai nilai prediksi dari sample uji yang baru. Dekat atau jauhnya tetangga biasanya dihitung berdasarkan jarak Eucledian. Algoritma metode KNN sangatlah sederhana, bekerja dengan berdasarkan pada jarak terpendek dari sample uji ke sample latih untuk menentukan KNN nya. Setelah mengumpulkan KNN, kemudian diambil mayoritas dari KNN untuk dijadikan prediksi dari sample uji.","title":"Apa itu k-NN?"},{"location":"nearestneighbors/#langkah-langkah-k-nn","text":"Tentukan jumlah kelompok neighbors (K) nya. Umumnya adalah 5. Ambil data K terdekat (K neighbors) dari data terbaru (umumnya 5 buah K) berdasarkan jarak euclidean antar keduanya. Dari K-neighbors ini, hitung berapa banyak data poin yang masuk di masing-masing kategori. Masukkan data baru ini ke dalam kelompok yang memiliki jumlah K-neighbors terbanyak","title":"Langkah - langkah k-NN"},{"location":"nearestneighbors/#kelebihan-dan-kekurangan-k-nn","text":"Kelebihan k-NN : memiliki beberapa kelebihan yaitu bahwa dia tangguh terhadap training data yang noisy dan efektif apabila data latih nya besar. Kelemahan dari k-NN k-NN perlu menentukan nilai dari parameter K (jumlah dari tetangga terdekat) Pembelajaran berdasarkan jarak tidak jelas mengenai jenis jarak apa yang harus digunakan dan atribut mana yang harus digunakan untuk mendapatkan hasil yang terbaik Biaya komputasi cukup tinggi karena diperlukan perhitungan jarak dari tiap sample uji pada keseluruhan sample latih.","title":"Kelebihan dan Kekurangan k-NN"},{"location":"nearestneighbors/#studi-kasus","text":"Seorang pemilik toko hp ingin mecari tahu solusi iklan di internet, di mana ia memiliki data pelanggannya. Melalui data penghasilan dan usia. Pemilik hp tersebut ingin mengiklankan produknya di kelompok yang memiliki kemungkinan untuk membeli hp nya lebih tinggi. Sehingga nantinya klasifikasi ini bisa digunakan oleh pemilik toko hp untuk semakin memperkuat hubungan mereka terhadap konsumen. Misal untuk penguatan marketing, strategi penawaran yang tepat, tipe hp apa saja yang cocok bagi mereka, dll.","title":"Studi Kasus"},{"location":"nearestneighbors/#kebutuhan","text":"Sebelum memulai project sebaiknya lakukan hal - hal berikut, jika sudah silahkan bisa langsung menuju ke script program di bawah. install bahasa pemrograman python, bisa anda download di sini Dataset csv, bisa anda download datasetnya di sini . Install numpy menggunakan pip : pip install numpy Install matplotlib menggunakan pip : pip install matplotlib Install pandas menggunakan pip : pip install pandas","title":"Kebutuhan"},{"location":"nearestneighbors/#script-program","text":"# Mengimpor library import numpy as np import matplotlib.pyplot as plt import pandas as pd # Mengimpor dataset dataset = pd.read_csv('Data_Customers_HP.csv') X = dataset.iloc[:, [2, 3]].values y = dataset.iloc[:, 4].values # Membagi dataset menjadi Training set and Test set from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) # Feature Scaling from sklearn.preprocessing import StandardScaler sc = StandardScaler() X_train = sc.fit_transform(X_train) X_test = sc.transform(X_test) # Membuat model k-NN from sklearn.neighbors import KNeighborsClassifier classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2) classifier.fit(X_train, y_train) # Memprediksi Test set y_pred = classifier.predict(X_test) # Membuat Confusion Matrix from sklearn.metrics import confusion_matrix cm = confusion_matrix(y_test, y_pred) # Visualisasi hasil Training set from matplotlib.colors import ListedColormap X_set, y_set = X_train, y_train X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01)) plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('grey', 'black'))) plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('yellow', 'red'))(i), label = j) plt.title('K-NN (Training set)') plt.xlabel('Usia') plt.ylabel('Penghasilan/bulan') plt.legend() plt.show()","title":"Script Program"},{"location":"nearestneighbors/#penjelasan-script","text":"Line 1-4 mengimpor library yang diperlukan. Line 7 mengimpor dataset. Line 8 mendefinisikan variabel X yaitu kolom usia dan penghasilan/bulan. Line 9 mendefinisikan variabel y yaitu keputusan beli/tidak. Line 12 mengimpor library dari sklearn untuk membagi dataset ke dalam training dan test set dengan konfigurasi 75:25 dan random number generator 0. Line 13 mendefinisikan variabel training dan test set. Line 16-19 melakukan feature scaling. Line 22 mengimpor library k-NN. Line 23 adalah mendefinisikan variabel classifier sebagai model k-NN. T kita memilih jumlah K 5 sesuai default nya. Kemudian metric kit pilih \u2018minkowski\u2019, dan p kita isi 2, karena menggunakan euclidean distance Line 24 mengaplikasikan model ini terhadap X_train dan y_train, karena kita ingin melatih modelnya dari training set. Line 27 adalah mendefinisikan variabel y_pred untuk memprediksi test set. Kita memprediksinya dari X_test, yang nantinya y_pred ini akan dibandingkan dengan y_test. Jika y_pred hasilnya mendekati y_test, maka bisa disimpulkan performanya cukup baik. Line 30 mengimpor library confusion_matrix dari sklearn untuk membuat confusion_matrix (CM)-nya. CM adalah perbandingan antara benar dan salah antara y_pred dengan y_test. Line 31 membuat variabel cm sebagai confusion matrix nya. Line 34-49 adalah perintah untuk visualisasi model k-NN terhadap training set. Hasilnya akan tampak sebagai berikut: Tampilan model k-NN dari training set. Gambar ini adalah hasil prediksi keputusan beli/tidak berdasarkan usia dan penghasilan/bulan yang dimiliki customers. Pada gambar di atas dapat kita lihat bahwa zona abu-abu adalah kelompok di mana pelanggan memutuskan untuk tidak membeli, sementara zona hitam adalah kelompok pelanggan memutuskan untuk membeli. Titik-titik kuning adalah data-data pelanggan yang memutuskan untuk tidak membeli, sedangkan titik-titik merah adalah data-data pelanggan yang memutuskan untuk membeli.","title":"Penjelasan Script"}]}